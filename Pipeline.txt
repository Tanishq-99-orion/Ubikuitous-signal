#trying to optimize this code

import os
import json
import requests
import concurrent.futures
from tqdm import tqdm
from collections import defaultdict, OrderedDict
import pandas as pd
import contextlib
import io

# =========================
# pgmpy imports
# =========================
from pgmpy.models import DiscreteBayesianNetwork
from pgmpy.factors.discrete import TabularCPD

# =========================
# GLOBAL THREAD POOL
# =========================
GLOBAL_EXECUTOR = concurrent.futures.ThreadPoolExecutor(max_workers=8)

def async_call(fn, *args, **kwargs):
    return GLOBAL_EXECUTOR.submit(fn, *args, **kwargs)

# =========================
# LINKAGE CANONICALIZATION
# =========================
LINKAGE_CANONICAL_MAP = {
    "M1": "M1_linear",
    "linear": "M1_linear"
}

def canonicalize_linkage(l):
    return LINKAGE_CANONICAL_MAP.get(l, l)

# =========================
# LOAD BIOLOGICAL FUNCTIONS
# =========================
FUNCTIONS_PATH = "/content/Functions required to predict ubiquitin linkage type.txt"

_ns = {"__name__": "__not_main__"}
with open(FUNCTIONS_PATH, "r", encoding="utf-8") as fh:
    code = fh.read()

# silence prints from function definitions
with contextlib.redirect_stdout(io.StringIO()):
    exec(compile(code, FUNCTIONS_PATH, "exec"), _ns)

def get_fn(name):
    if name not in _ns:
        raise RuntimeError(f"Required function '{name}' not found in functions file")
    return _ns[name]

# =========================
# IMPORT REQUIRED FUNCTIONS
# =========================
gene_symbol_to_uniprot = get_fn("gene_symbol_to_uniprot")
get_e2s_from_reactome = get_fn("get_e2s_from_reactome")
get_e2s_from_biogrid = get_fn("get_e2s_from_biogrid")
get_go_terms_from_uniprot = get_fn("get_go_terms_from_uniprot")
score_e2_type = get_fn("score_e2_type")
get_accessible_lysines = get_fn("get_accessible_lysines")
analyze_substrate = get_fn("analyze_substrate")
infer_local_dub_activity = get_fn("infer_local_dub_activity")
biochemical_linkage_override = get_fn("biochemical_linkage_override")
apply_temporal_gate_explicit = get_fn("apply_temporal_gate_explicit")
get_canonical_gene_symbol = get_fn("get_canonical_gene_symbol")
get_ubibrowser_term_from_uniprot = get_fn("get_ubibrowser_term_from_uniprot")
get_e3_class_from_ubibrowser = get_fn("get_e3_class_from_ubibrowser")

# ---- Infinity Stone 10 (already inside functions file) ----
map_linkage_to_process = get_fn("map_linkage_to_process")
find_prior_files = get_fn("find_prior_files")
load_priors = get_fn("load_priors")
CELL_TYPE_CHOICES = get_fn("CELL_TYPE_CHOICES")

E3_POLYUB_SCORE = _ns.get("E3_POLYUB_SCORE", {})

# =========================
# HELPERS
# =========================
def resolve_e3_uniprot_and_gene(e3_input):
    if e3_input.upper().startswith(("Q", "P")):
        return e3_input, get_canonical_gene_symbol(e3_input)
    return gene_symbol_to_uniprot(e3_input), e3_input

def pick_top_e2s(e2s, top_n):
    return sorted(e2s)[:top_n]

def fetch_go_safe(ac):
    try:
        return get_go_terms_from_uniprot(ac) or []
    except Exception:
        return []

# =========================
# MAIN PIPELINE
# =========================
def run_pipeline(
    substrate_uniprot,
    e3_input,
    cell_state,
    cell_type,
    top_n_e2=3,
    output_prefix="/mnt/data/ubiquitin_pipeline"
):

    print("\n==============================")
    print(" UBIQUITIN LINKAGE PIPELINE ")
    print("==============================")

    # -------------------------
    # Resolve E3
    # -------------------------
    e3_uniprot, e3_gene = async_call(
        resolve_e3_uniprot_and_gene, e3_input
    ).result()

    print(f"\nResolved E3 → Gene: {e3_gene}, UniProt: {e3_uniprot}")

    # -------------------------
    # E3 class & poly prior
    # -------------------------
    poly_prior = 0.3
    if e3_uniprot:
        with contextlib.redirect_stdout(io.StringIO()):
            term = get_ubibrowser_term_from_uniprot(e3_uniprot)
            if term:
                cls = get_e3_class_from_ubibrowser(term)
                poly_prior = E3_POLYUB_SCORE.get(cls, poly_prior)

    print(f"E3 polyubiquitination prior: {poly_prior}")

    # -------------------------
    # Get E2s
    # -------------------------
    try:
        e2s = get_e2s_from_reactome()
        source = "Reactome"
    except Exception:
        e2s = get_e2s_from_biogrid(e3_gene)
        source = "BioGRID"

    top_e2s = pick_top_e2s(e2s, top_n_e2)
    print(f"E2 source: {source}")
    print(f"Top E2s used: {top_e2s}")

    # -------------------------
    # Score E2s
    # -------------------------
    e2_details = {}
    futures = {
        async_call(gene_symbol_to_uniprot, e2): e2
        for e2 in top_e2s
    }

    for fut in tqdm(concurrent.futures.as_completed(futures),
                    total=len(futures),
                    desc="Resolving & scoring E2s"):
        e2 = futures[fut]
        acc = fut.result()
        go = fetch_go_safe(acc)
        etype, score = score_e2_type(e2, go)
        e2_details[e2] = {"uniprot": acc, "type": etype, "score": score}

    # -------------------------
    # Substrate analysis
    # -------------------------
    lys_cat, lys_det = get_accessible_lysines(substrate_uniprot)
    substrate_gene = get_canonical_gene_symbol(substrate_uniprot)
    residence = analyze_substrate(substrate_uniprot, substrate_gene)

    print(f"\nAccessible lysines: {lys_cat}")
    print(f"Residence analysis: {residence}")

    # -------------------------
    # Local DUB activity
    # -------------------------
    local_dub_state, local_dub_evidence = infer_local_dub_activity(
        substrate_uniprot, e3_uniprot
    )

    print(f"Local DUB activity: {local_dub_state}")

    # -------------------------
    # Biochemical aggregation
    # -------------------------
    agg = defaultdict(float)

    for e2 in top_e2s:
        res = biochemical_linkage_override(
            substrate_uniprot,
            e3_gene,
            e2_gene=e2,
            local_dubs=list(local_dub_evidence.get("DUBs", {}).keys()),
        )
        for k, v in res.get("scores", {}).items():
            agg[canonicalize_linkage(k)] += float(v)

    if not agg:
        agg = {
            "K48": 0.5 * poly_prior,
            "K63": 0.3 * poly_prior,
            "mono": 0.2
        }

    total = sum(max(v, 0) for v in agg.values()) or 1.0
    probs = {k: max(v, 0) / total for k, v in agg.items()}

    print("\nBiochemical linkage probabilities (pre-gate):")
    for k, v in sorted(probs.items(), key=lambda x: -x[1]):
        print(f"  {k}: {v:.4f}")

    # -------------------------
    # Temporal gate
    # -------------------------
    gated, gate_info = apply_temporal_gate_explicit(probs, cell_state)

    if gated and sum(gated.values()) > 0:
        final = {k: v / sum(gated.values()) for k, v in gated.items()}
    else:
        final = probs

    print(f"\nAfter temporal gate ({cell_state}):")
    for k, v in sorted(final.items(), key=lambda x: -x[1]):
        print(f"  {k}: {v:.4f}")

    # -------------------------
    # Dominant linkage
    # -------------------------
    dominant_linkage = max(final, key=final.get)
    print(f"\nDominant predicted linkage → {dominant_linkage}")

    # -------------------------
    # INFINITY STONE 10
    # -------------------------
    prior_files = find_prior_files()
    priors_dict = load_priors(prior_files)

    process_df, process_meta = map_linkage_to_process(
        cell_type=cell_type,
        linkage=dominant_linkage,
        priors_dict=priors_dict
    )

    # ==========================================================
    # FINAL BIOLOGICAL INTERPRETATION (PROCESS LEVEL)
    # ==========================================================

    top_process = process_df.iloc[0]
    top_name = top_process["Process"]
    top_prob = top_process["Posterior"]

    # Optional: group processes into higher-level biology
    PROCESS_GROUPS = {
        "proteasome": "proteasome-related process",
        "lysosome": "lysosome-related process",
        "autophagy": "lysosome/autophagy-related process",
        "escrt": "endosomal ESCRT-mediated process",
        "recycling": "recycling / trafficking process",
        "deubiquitination": "deubiquitination-dominated process",
    }

    process_label = PROCESS_GROUPS.get(
        top_name.lower(),
        f"{top_name}-related process"
    )

    # Confidence wording
    if top_prob >= 0.6:
        confidence = "strongly"
    elif top_prob >= 0.4:
        confidence = "moderately"
    else:
        confidence = "weakly"

    print("\n==============================")
    print(" FINAL BIOLOGICAL INTERPRETATION")
    print("==============================")
    print(
        f"This substrate ubiquitination event is {confidence} biased toward a "
        f"{process_label}."
    )
    print(f"(Posterior probability = {top_prob:.3f})")

    print("\n==============================")
    print(" PROCESS INFERENCE (IS-10) ")
    print("==============================")
    print(f"Cell type : {cell_type}")
    print(f"Linkage   : {dominant_linkage}\n")

    print(
        process_df[
            [
                "Process",
                "Posterior",
                "Prior_given_cell",
                "P_linkage_given_process",
                "Survival_factor"
            ]
        ].to_string(index=False)
    )

    return {
        "linkage_probs": final,
        "dominant_linkage": dominant_linkage,
        "process_df": process_df
    }
# =========================
# Adjusting timeoff
# =========================
DEGPRED_URL = _ns["DEGPRED_URL"]

# Redefine parse_degpred with an increased timeout (e.g., 60 seconds)
def parse_degpred_with_longer_timeout(uniprot_id):
    url = DEGPRED_URL.format(uniprot_id)
    # Increased timeout from 20 to 60 seconds
    r = requests.get(url, timeout=60)
    r.raise_for_status()
    return r.json()

# Update the _ns dictionary with the new function
# This ensures that `analyze_substrate` and any other functions relying on
# `parse_degpred` will use this modified version.
_ns["parse_degpred"] = parse_degpred_with_longer_timeout

print("parse_degpred function updated with a 60-second timeout.")

# =========================
# USER INPUT
# =========================
if __name__ == "__main__":

    substrate_uniprot = input("Enter substrate UniProt ID: ").strip()
    e3_input = input("Enter E3 gene or UniProt ID: ").strip()

    print("\nCell state:")
    print("1 - DNA_damage")
    print("2 - cycling")
    print("3 - immune_active")
    print("4 - quiescent")

    cell_state = {
        "1": "DNA_damage",
        "2": "cycling",
        "3": "immune_active",
        "4": "quiescent"
    }[input("Choice: ").strip()]

    print("\nSelect cell type:")
    for i, ct in enumerate(CELL_TYPE_CHOICES):
        print(f" [{i}] {ct}")
    cell_type = CELL_TYPE_CHOICES[int(input("Choice: ").strip())]

    top_n = input("Top N E2s (default 3): ").strip()
    top_n = int(top_n) if top_n else 3

    run_pipeline(
        substrate_uniprot,
        e3_input,
        cell_state,
        cell_type,
        top_n_e2=top_n
    )
